{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d644c4a0bd94b1e8483d8cbaedeb1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f3ad66ab32b4175b1ed7d503764a953",
              "IPY_MODEL_a33d31da810b4ac484bf6bd4dbbe5f66",
              "IPY_MODEL_f744d02ebf1344b387556389f8d610d0"
            ],
            "layout": "IPY_MODEL_c9a2bd617e5d4eb18fc82074933f55da"
          }
        },
        "9f3ad66ab32b4175b1ed7d503764a953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f445b678a85a4024a65dcb22a55922f1",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb2af99026d471e93775b5b72b9f343",
            "value": "Map: 100%"
          }
        },
        "a33d31da810b4ac484bf6bd4dbbe5f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326d6e6e09194ab3bf6dd49b4399e0bc",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39a6765c11ba4cca822cdc3c993e6673",
            "value": 1000
          }
        },
        "f744d02ebf1344b387556389f8d610d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea3101ea2c44977ae4e77f6407ef881",
            "placeholder": "​",
            "style": "IPY_MODEL_eb8054727f60470cad0822f57273197a",
            "value": " 1000/1000 [00:00&lt;00:00, 2716.58 examples/s]"
          }
        },
        "c9a2bd617e5d4eb18fc82074933f55da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f445b678a85a4024a65dcb22a55922f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb2af99026d471e93775b5b72b9f343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "326d6e6e09194ab3bf6dd49b4399e0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a6765c11ba4cca822cdc3c993e6673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cea3101ea2c44977ae4e77f6407ef881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8054727f60470cad0822f57273197a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab2d5fca2274cf9b3fcdcbdeff77f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7ca88eb11b4642b3c7954858134b03",
              "IPY_MODEL_0535dd2e3d664829bb478aabefaa8a47",
              "IPY_MODEL_9d3e74378d1c47b091e9dea226ad6221"
            ],
            "layout": "IPY_MODEL_5800f812a3df4f9e98f1de435c439fe0"
          }
        },
        "3e7ca88eb11b4642b3c7954858134b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369da3488a63477886d105164dfb7cd5",
            "placeholder": "​",
            "style": "IPY_MODEL_416f0147dc6b4d08b550b13a9fe3de1a",
            "value": "Map: 100%"
          }
        },
        "0535dd2e3d664829bb478aabefaa8a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970f2dc4d63546b38cc29dd7cee8b0f6",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f15e55e45f8e4097a1e6749f114e7b39",
            "value": 1000
          }
        },
        "9d3e74378d1c47b091e9dea226ad6221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e1edcbb7ee94493b5a48b6002480945",
            "placeholder": "​",
            "style": "IPY_MODEL_1d10bed373ea4e4d8378ff727d418dd1",
            "value": " 1000/1000 [00:00&lt;00:00, 3606.05 examples/s]"
          }
        },
        "5800f812a3df4f9e98f1de435c439fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369da3488a63477886d105164dfb7cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416f0147dc6b4d08b550b13a9fe3de1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "970f2dc4d63546b38cc29dd7cee8b0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15e55e45f8e4097a1e6749f114e7b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e1edcbb7ee94493b5a48b6002480945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d10bed373ea4e4d8378ff727d418dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s9tRq_bSD2h2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31oKOET_EJkG",
        "outputId": "a6bbb78e-a802-411a-c0d2-97972043d9c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load Subsets\n",
        "labeled_final = load_dataset(\"paws\", \"labeled_final\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ6y8ghsEVJN",
        "outputId": "3d764319-929a-4e6f-8f6b-323223eec2a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7yEtwmzEbJx",
        "outputId": "7be55605-c55b-4251-b795-6ce042370159"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
              "        num_rows: 49401\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
              "        num_rows: 8000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
              "        num_rows: 8000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Access train, test, and validation splits\n",
        "# labeled_final_train = labeled_final[\"train\"]\n",
        "# labeled_final_test = labeled_final[\"test\"]\n",
        "# labeled_final_validation = labeled_final[\"validation\"]"
      ],
      "metadata": {
        "id": "H-5ZdtVYmOHW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text preprocessing function\n",
        "def preprocess_text(data):\n",
        "  for eachsent in range(len(data['sentence1'])):\n",
        "\n",
        "    # 1. Remove extra spaces\n",
        "    data['sentence1'][eachsent] = re.sub(r'\\s+', ' ', data['sentence1'][eachsent].strip())\n",
        "\n",
        "    # 2. Remove unwanted text (e.g., URLs, special characters, digits)\n",
        "    data['sentence1'][eachsent] = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', data['sentence1'][eachsent])  # Remove URLs\n",
        "    #data['sentence1'][eachsent] = re.sub(r'[^\\w\\s]', '', data['sentence1'][eachsent])  # Remove special characters (punctuation)\n",
        "\n",
        "    # 3. Convert to lowercase\n",
        "    data['sentence1'][eachsent] = data['sentence1'][eachsent].lower()\n",
        "\n",
        "    # 4. Normalize text (e.g., contractions)\n",
        "    contractions = {\"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"}\n",
        "    data['sentence1'][eachsent] = ' '.join([contractions[word] if word in contractions else word for word in data['sentence1'][eachsent].split()])\n",
        "\n",
        "\n",
        "  for eachsent in range(len(data['sentence2'])):\n",
        "\n",
        "    # 1. Remove extra spaces\n",
        "    data['sentence2'][eachsent] = re.sub(r'\\s+', ' ', data['sentence2'][eachsent].strip())\n",
        "\n",
        "    # 2. Remove unwanted text (e.g., URLs, special characters, digits)\n",
        "    data['sentence2'][eachsent] = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', data['sentence2'][eachsent])  # Remove URLs\n",
        "    #data['sentence2'][eachsent] = re.sub(r'[^\\w\\s]', '', data['sentence2'][eachsent])  # Remove special characters (punctuation)\n",
        "\n",
        "    # 3. Convert to lowercase\n",
        "    data['sentence2'][eachsent] = data['sentence1'][eachsent].lower()\n",
        "\n",
        "    # 4. Normalize text (e.g., contractions)\n",
        "    contractions = {\"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"}\n",
        "    data['sentence2'][eachsent] = ' '.join([contractions[word] if word in contractions else word for word in data['sentence2'][eachsent].split()])\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "V96GIDqXlf_M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = labeled_final[\"train\"].map(preprocess_text, batched=True)\n",
        "valid_dataset = labeled_final[\"validation\"].map(preprocess_text, batched=True)\n",
        "test_dataset = labeled_final[\"test\"].map(preprocess_text, batched=True)"
      ],
      "metadata": {
        "id": "cWNdB7aQlnV8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train = labeled_final['train'].select(range(500))\n",
        "# test = labeled_final['test'].select(range(50))\n",
        "# valid = labeled_final['validation'].select(range(50))\n",
        "\n",
        "train = train_dataset.select(range(1000))\n",
        "valid = valid_dataset.select(range(50))\n",
        "test = test_dataset.select(range(50))\n"
      ],
      "metadata": {
        "id": "txQCAfdbEea2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "movzRa15Emlj",
        "outputId": "2a5875de-02d9-45a9-c5f1-5c07dd5526f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 1,\n",
              " 'sentence1': 'in paris , in october 1560 , he secretly met the english ambassador , nicolas throckmorton , asking him for a passport to return to england through scotland .',\n",
              " 'sentence2': 'in paris , in october 1560 , he secretly met the english ambassador , nicolas throckmorton , asking him for a passport to return to england through scotland .',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN= userdata.get('HuggingFace')\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "YIsyFV_1GTEE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "oGIyf_iwHfkn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since LLAMA3 pre-training doesn't have EOS token\n",
        "* Set the pad_token_id to eos_token_id\n",
        "* Set pad token ot eos_token"
      ],
      "metadata": {
        "id": "Mw9Vgwlj3GlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# # Load the model\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZclzrnCqFAvn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJPWlR9Ekt10",
        "outputId": "0e37dabe-ec5e-4935-c718-8b550d3bd973"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Incase of quantization\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "\n",
        "# Define QLORA configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,  # Use 4-bit precision\n",
        "    bnb_4bit_use_double_quant=True,  # Double quantization for stability\n",
        "    bnb_4bit_quant_type=\"nf4\",  # Quantization type (e.g., NormalFloat4)\n",
        "    bnb_4bit_compute_dtype=torch.float16  # Computation type\n",
        ")\n",
        "\n",
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=8,                          # Low-rank size\n",
        "    lora_alpha=32,                # LoRA scaling factor\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers (specific to LLaMA)\n",
        "    lora_dropout=0.1,             # Dropout for LoRA layers\n",
        "    bias=\"none\",                  # No bias adaptation\n",
        "    task_type=\"SEQ_CLS\"         # Task type: causal language modeling ###'SEQ_CLS' ###CAUSAL_LM\n",
        ")\n",
        "\n",
        "# Load Model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    num_labels=2,  # Explicitly set for binary classification\n",
        "    device_map=\"auto\"  # Automatically distribute layers across available GPUs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jbWjN-piTpS",
        "outputId": "93020ce8-cc59-4c5e-f0a2-f70297d62ed5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call the prepare_model_for_kbit_training() function to preprocess the quantized model for training.\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "\n",
        "#use the get_peft_model() function to create a PeftModel from the quantized model and configuration.\n",
        "from peft import get_peft_model\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "JTLO9KZFyT3N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update some model configs\n",
        "* Must use .cache = False as below or it crashes from my experience"
      ],
      "metadata": {
        "id": "pD5boHFW3SZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "id": "e5NlmHCL3VK1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# # Wrap the model with LoRA\n",
        "# model = get_peft_model(model, lora_config)\n",
        "\n",
        "# # Freeze all model parameters except LoRA layers\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # Enable gradients for LoRA layers\n",
        "# for name, param in model.named_parameters():\n",
        "#     if \"lora\" in name:\n",
        "#         param.requires_grad = True\n",
        "\n",
        "# # Check which parameters require gradients\n",
        "# for name, param in model.named_parameters():\n",
        "#     print(f\"{name} requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "C8dUI3CiQMfH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "m6ZF1J0VynNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure tokenizer has a pad_token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    print(\"Padding token added as [PAD].\")\n",
        "\n",
        "# Resize model embeddings if new token is added\n",
        "if tokenizer.pad_token_id is not None and model.get_input_embeddings().num_embeddings != len(tokenizer):\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Set pad_token_id in model configuration\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"sentence1\"],\n",
        "        examples[\"sentence2\"],\n",
        "        padding=\"max_length\",  # Use padding\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_train_dataset = train.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7d644c4a0bd94b1e8483d8cbaedeb1cb",
            "9f3ad66ab32b4175b1ed7d503764a953",
            "a33d31da810b4ac484bf6bd4dbbe5f66",
            "f744d02ebf1344b387556389f8d610d0",
            "c9a2bd617e5d4eb18fc82074933f55da",
            "f445b678a85a4024a65dcb22a55922f1",
            "6fb2af99026d471e93775b5b72b9f343",
            "326d6e6e09194ab3bf6dd49b4399e0bc",
            "39a6765c11ba4cca822cdc3c993e6673",
            "cea3101ea2c44977ae4e77f6407ef881",
            "eb8054727f60470cad0822f57273197a"
          ]
        },
        "id": "LGfkF13QGkat",
        "outputId": "e13e3812-dde5-4884-a068-83204d760b14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d644c4a0bd94b1e8483d8cbaedeb1cb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tygA1OJIB8x",
        "outputId": "5b81ba43-98b2-4a49-d823-e4ac09381e2b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'sentence1', 'sentence2', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test_dataset = test.map(tokenize_function, batched=True)\n",
        "tokenized_valid_dataset = valid.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "BQ_9M2DHIc3d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the necessary features\n",
        "tokenized_train_dataset = tokenized_train_dataset.map(\n",
        "    lambda examples: {\n",
        "        \"input_ids\": examples[\"input_ids\"],\n",
        "        \"attention_mask\": examples[\"attention_mask\"],\n",
        "        \"labels\": examples[\"label\"]\n",
        "    },\n",
        "    remove_columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
        ")\n",
        "tokenized_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "9ab2d5fca2274cf9b3fcdcbdeff77f50",
            "3e7ca88eb11b4642b3c7954858134b03",
            "0535dd2e3d664829bb478aabefaa8a47",
            "9d3e74378d1c47b091e9dea226ad6221",
            "5800f812a3df4f9e98f1de435c439fe0",
            "369da3488a63477886d105164dfb7cd5",
            "416f0147dc6b4d08b550b13a9fe3de1a",
            "970f2dc4d63546b38cc29dd7cee8b0f6",
            "f15e55e45f8e4097a1e6749f114e7b39",
            "5e1edcbb7ee94493b5a48b6002480945",
            "1d10bed373ea4e4d8378ff727d418dd1"
          ]
        },
        "id": "rZG5RMq9JCUf",
        "outputId": "1be0881d-0231-4847-960a-47038d82f29a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ab2d5fca2274cf9b3fcdcbdeff77f50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the necessary features\n",
        "tokenized_valid_dataset = tokenized_valid_dataset.map(\n",
        "    lambda examples: {\n",
        "        \"input_ids\": examples[\"input_ids\"],\n",
        "        \"attention_mask\": examples[\"attention_mask\"],\n",
        "        \"labels\": examples[\"label\"]\n",
        "    },\n",
        "    remove_columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
        ")\n",
        "\n",
        "tokenized_valid_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCLGlo0HJTGl",
        "outputId": "2260665b-b251-48e6-c366-2338fc53c6f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 50\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Keep only the necessary features\n",
        "# tokenized_test_dataset = tokenized_test_dataset.map(\n",
        "#     lambda examples: {\n",
        "#         \"input_ids\": examples[\"input_ids\"],\n",
        "#         \"attention_mask\": examples[\"attention_mask\"],\n",
        "#         \"labels\": examples[\"label\"]\n",
        "#     },\n",
        "#     remove_columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
        "# )\n",
        "\n",
        "tokenized_test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81b0LcPZJdBT",
        "outputId": "ff12c448-c2a9-4fd2-b4e4-95decc9df2d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'sentence1', 'sentence2', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 50\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator for padding\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "CJuMmxT2zMrL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# disable Weights and Biases\n",
        "os.environ['WANDB_DISABLED']=\"true\"\n"
      ],
      "metadata": {
        "id": "70GeXdlTKwN5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_lora\",         # Output directory for saved models\n",
        "    learning_rate=2e-5,          # Learning rate\n",
        "    per_device_train_batch_size=4, # Training batch size\n",
        "    per_device_eval_batch_size=4, # Evaluation batch size\n",
        "    num_train_epochs=5,            # Number of training epochs\n",
        "    weight_decay=0.01,             # Weight decay\n",
        "    #save_total_limit=2,            # Save only the 2 most recent models\n",
        "    logging_dir=\"./logs\",          # Log directory\n",
        "    logging_steps=50,              # Log every 50 steps\n",
        "    load_best_model_at_end=True,    # Load the best model at the end of training\n",
        "    eval_strategy=\"epoch\",   # Evaluate after each epoch\n",
        "    save_strategy=\"epoch\",         # Change save_strategy to 'epoch' to match eval_strategy\n",
        "    #gradient_accumulation_steps=2, # Added gradient accumulation\n",
        "    #fp16=False,                       # Enabled mixed precision training\n",
        "    #gradient_checkpointing=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFR3LQtfJihO",
        "outputId": "b4bfa708-dac1-48e8-abe5-30b1b93a60af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARn_PCD7QboB",
        "outputId": "fc3ba8ba-57a8-4d7e-c0c5-8d69fa806d82"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 856,064 || all params: 1,236,674,560 || trainable%: 0.0692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Define a metric function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)  # Get the class with the highest score\n",
        "\n",
        "    # Calculate accuracy, precision, recall, and F1\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ],
      "metadata": {
        "id": "O9Km97MtYGGl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_valid_dataset,  # Assuming you have a validation set\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkJJhz__Jtxt",
        "outputId": "7a66078e-a0ca-4900-c43b-99b5ed277c27"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-799c2d17add1>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyt8O7P0PYO5",
        "outputId": "b6e857d4-48cb-43fc-834e-0df6ea5c9112"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 18 09:20:14 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0              33W /  70W |   2139MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "7rO1PIgHKkRP",
        "outputId": "9e38d085-26e7-4608-f389-858657f49070"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 22:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.775200</td>\n",
              "      <td>0.815398</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.372093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.784900</td>\n",
              "      <td>0.760804</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.530612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.682600</td>\n",
              "      <td>0.738576</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.642900</td>\n",
              "      <td>0.743950</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.346154</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.589600</td>\n",
              "      <td>0.742243</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.7023217407226563, metrics={'train_runtime': 1345.8462, 'train_samples_per_second': 3.715, 'train_steps_per_second': 0.929, 'total_flos': 3740184084480000.0, 'train_loss': 0.7023217407226563, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(\"Evaluation Results:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "UP0UkOrJKk06",
        "outputId": "5d4eeb00-1179-40f4-99e2-fbed94d42929"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 0.7385758757591248, 'eval_accuracy': 0.52, 'eval_precision': 0.5384615384615384, 'eval_recall': 0.5384615384615384, 'eval_f1': 0.5384615384615384, 'eval_runtime': 4.5666, 'eval_samples_per_second': 10.949, 'eval_steps_per_second': 2.847, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.predict(tokenized_test_dataset)\n",
        "metrics = compute_metrics(test_results)\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SjSMUUBBXlKg",
        "outputId": "461ba68d-9848-4c43-9e04-e0e1caa10f89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.56, 'precision': 0.4117647058823529, 'recall': 0.3684210526315789, 'f1': 0.3888888888888889}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the test set\n",
        "predictions = test_results.predictions.argmax(-1)  # Predicted labels\n",
        "true_labels = test_results.label_ids               # True labels\n",
        "\n",
        "# Pair predictions with true labels\n",
        "for i in range(len(predictions)):\n",
        "    print(f\"Sentence1: {tokenized_test_dataset[i]['sentence1']}\")\n",
        "    print(f\"Sentence2: {tokenized_test_dataset[i]['sentence2']}\")\n",
        "    print(f\"True Label: {true_labels[i]}, Predicted Label: {predictions[i]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zcyXI-EYxBr",
        "outputId": "71b66bb3-a1b5-4312-8b9b-576104fdcc6a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: this was a series of nested angular standards , so that measurements in azimuth and elevation could be done directly in polar coordinates relative to the ecliptic .\n",
            "Sentence2: this was a series of nested angular standards , so that measurements in azimuth and elevation could be done directly in polar coordinates relative to the ecliptic .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: his father emigrated to missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to america .\n",
            "Sentence2: his father emigrated to missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to america .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: in january 2011 , the deputy secretary general of fiba asia , hagop khajirian , inspected the venue together with sbp - president manuel v. pangilinan .\n",
            "Sentence2: in january 2011 , the deputy secretary general of fiba asia , hagop khajirian , inspected the venue together with sbp - president manuel v. pangilinan .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: steiner argued that , in the right circumstances , the spiritual world can be explored through direct experience by practicing ethical and cognitive forms of rigorous self-discipline .\n",
            "Sentence2: steiner argued that , in the right circumstances , the spiritual world can be explored through direct experience by practicing ethical and cognitive forms of rigorous self-discipline .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: luciano williames dias ( born july 25 , 1970 ) is a brazilian football coach and former player .\n",
            "Sentence2: luciano williames dias ( born july 25 , 1970 ) is a brazilian football coach and former player .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: during her sophomore , junior and senior summers , she spent half of it with her alaska team , and half playing , and living in oregon .\n",
            "Sentence2: during her sophomore , junior and senior summers , she spent half of it with her alaska team , and half playing , and living in oregon .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: the smallest number that can be represented in two positive and seventh ways as a sum of four different powers is 2056364173794800 .\n",
            "Sentence2: the smallest number that can be represented in two positive and seventh ways as a sum of four different powers is 2056364173794800 .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: his father emigrated to missouri in 1868 , but returned when his wife became ill and before the rest of the family could go to america .\n",
            "Sentence2: his father emigrated to missouri in 1868 , but returned when his wife became ill and before the rest of the family could go to america .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: the villa pesquera facilities are owned by the municipality of ponce , but operated by the fishermen themselves .\n",
            "Sentence2: the villa pesquera facilities are owned by the municipality of ponce , but operated by the fishermen themselves .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: it is situated south of köroğlu mountains and to the north of bolu .\n",
            "Sentence2: it is situated south of köroğlu mountains and to the north of bolu .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: the río blanco mine is a large copper mine located in the north of peru in loreto region .\n",
            "Sentence2: the río blanco mine is a large copper mine located in the north of peru in loreto region .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: he appeared as general tao in the amazon - show `` the man at the high castle '' , and as onoda in amc `` hell on wheels '' .\n",
            "Sentence2: he appeared as general tao in the amazon - show `` the man at the high castle '' , and as onoda in amc `` hell on wheels '' .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: the spectral levels of light that can be measured by plants for photosynthesis is similar to , but not the same as what  is used by lumens .\n",
            "Sentence2: the spectral levels of light that can be measured by plants for photosynthesis is similar to , but not the same as what is used by lumens .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: the sunset sunset road comes from right and becomes briscoe mountain road .\n",
            "Sentence2: the sunset sunset road comes from right and becomes briscoe mountain road .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: to get there , take the marine drive from the lions gate bridge to the west , past lighthouse park , horseshoe bay and then further on to the 7100 marine drive block .\n",
            "Sentence2: to get there , take the marine drive from the lions gate bridge to the west , past lighthouse park , horseshoe bay and then further on to the 7100 marine drive block .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: inverallan is one of the parishes which formed the ecclesiastical ( later civil ) parish of `` cromdale , inverallan and advie '' in morayshire in scotland .\n",
            "Sentence2: inverallan is one of the parishes which formed the ecclesiastical ( later civil ) parish of `` cromdale , inverallan and advie '' in morayshire in scotland .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: mr. thuso nokwanda mbedu was born in pietermaritzburg as thuso mbebu .\n",
            "Sentence2: mr. thuso nokwanda mbedu was born in pietermaritzburg as thuso mbebu .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: for ideal gases , the molar volume is given by the ideal gas equation , a good approximation for many usual gases at standard temperature and pressure .\n",
            "Sentence2: for ideal gases , the molar volume is given by the ideal gas equation , a good approximation for many usual gases at standard temperature and pressure .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: john barrow island is a member of the queen elizabeth islands and the canadian arctic archipelago in the territory of nunavut .\n",
            "Sentence2: john barrow island is a member of the queen elizabeth islands and the canadian arctic archipelago in the territory of nunavut .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: it was chosen as the 19th best movie at the 7th yokohama film festival .\n",
            "Sentence2: it was chosen as the 19th best movie at the 7th yokohama film festival .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: christopher griffiths ( born christopher llewellyn ) is an actor , best known for his role as logan in the 2002 film `` where were we ... '' .\n",
            "Sentence2: christopher griffiths ( born christopher llewellyn ) is an actor , best known for his role as logan in the 2002 film `` where were we ... '' .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: netanya is located on the israeli mediterranean coastal plain , the historic land bridge between europe , africa , and asia .\n",
            "Sentence2: netanya is located on the israeli mediterranean coastal plain , the historic land bridge between europe , africa , and asia .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: owned by rick and sheri dorritie is megasaurus and owned by mike west transaurus .\n",
            "Sentence2: owned by rick and sheri dorritie is megasaurus and owned by mike west transaurus .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: all five events started the last day and concluded with the final on the first day .\n",
            "Sentence2: all five events started the last day and concluded with the final on the first day .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: in january 2011 , fiba asia deputy secretary general manuel v. pangilinan along with sbp president hagop khajirian inspected the venue .\n",
            "Sentence2: in january 2011 , fiba asia deputy secretary general manuel v. pangilinan along with sbp president hagop khajirian inspected the venue .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: the strong influence of attic-figure greek vase painting has convinced some experts that the artist who decorated the tomb was a red metic .\n",
            "Sentence2: the strong influence of attic-figure greek vase painting has convinced some experts that the artist who decorated the tomb was a red metic .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: a unique feature of the human metate is the lack of ceremonial figures .\n",
            "Sentence2: a unique feature of the human metate is the lack of ceremonial figures .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: durr was born in birmingham , alabama , where she was brought up by southern women , but was also taught that the ku klux klan were protectors of black femaleness .\n",
            "Sentence2: durr was born in birmingham , alabama , where she was brought up by southern women , but was also taught that the ku klux klan were protectors of black femaleness .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: katrina m. of sputinik music was positive and said that the song is reverse , bright and cheerful .\n",
            "Sentence2: katrina m. of sputinik music was positive and said that the song is reverse , bright and cheerful .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: the nokasippi river , the mississippi river and the little nokasippi river are all in the area .\n",
            "Sentence2: the nokasippi river , the mississippi river and the little nokasippi river are all in the area .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: in 2006 , the álvarez won the south america games against hamilton ventura .\n",
            "Sentence2: in 2006 , the álvarez won the south america games against hamilton ventura .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: some reports state `` 30 years or more '' , while others claim `` 50 years or more '' .\n",
            "Sentence2: some reports state `` 30 years or more '' , while others claim `` 50 years or more '' .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: the resignation of councillor horace muspratt ( party ? , st. peter , reported april 15 , 1908 ) was elected to the council on 2 june 1909 .\n",
            "Sentence2: the resignation of councillor horace muspratt ( party ? , st. peter , reported april 15 , 1908 ) was elected to the council on 2 june 1909 .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: on april 11 , 2011 , a like planet , hd 38283 b , was discovered in an earth-saturnian orbit .\n",
            "Sentence2: on april 11 , 2011 , a like planet , hd 38283 b , was discovered in an earth-saturnian orbit .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: on july 21 , 2014 , after his two successful years at las palmas in spain , chrisantus signed a three-year contract with the turkish super lig - club sivasspor .\n",
            "Sentence2: on july 21 , 2014 , after his two successful years at las palmas in spain , chrisantus signed a three-year contract with the turkish super lig - club sivasspor .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: ruben bolling ( born 1963 in new jersey ) is a pseudonym for cartoonist ken fisher , the author of `` tom the dancing bug '' .\n",
            "Sentence2: ruben bolling ( born 1963 in new jersey ) is a pseudonym for cartoonist ken fisher , the author of `` tom the dancing bug '' .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: on december 1 , tinnish announced that he had withdrawn from his position with toronto and would stay with atlanta .\n",
            "Sentence2: on december 1 , tinnish announced that he had withdrawn from his position with toronto and would stay with atlanta .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: located in the southern part of the county , it lies in the southeastern part of the state .\n",
            "Sentence2: located in the southern part of the county , it lies in the southeastern part of the state .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: he was born in new york city in east broadway on october 23 , 1806 .\n",
            "Sentence2: he was born in new york city in east broadway on october 23 , 1806 .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: he always added his own surname of bhosle and then treated the child like his own son .\n",
            "Sentence2: he always added his own surname of bhosle and then treated the child like his own son .\n",
            "True Label: 1, Predicted Label: 1\n",
            "\n",
            "Sentence1: after selling his house on 30 harare drive to the canadian embassy he bought bromley farm just outside marondera , zimbabwe .\n",
            "Sentence2: after selling his house on 30 harare drive to the canadian embassy he bought bromley farm just outside marondera , zimbabwe .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: the baldwins lived in washington , d.c. robert baldwin died in 1977 , and helen baldwin died march 14 , 1998 , from lou gehrig  is disease .\n",
            "Sentence2: the baldwins lived in washington , d.c. robert baldwin died in 1977 , and helen baldwin died march 14 , 1998 , from lou gehrig is disease .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: doyline is an entry point to lake bistineau and the bistineau state park .\n",
            "Sentence2: doyline is an entry point to lake bistineau and the bistineau state park .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: companies based in the larger rivium include rockwell automation , royal dutch shell , sodexho nederland , pfizer , van oord and many more .\n",
            "Sentence2: companies based in the larger rivium include rockwell automation , royal dutch shell , sodexho nederland , pfizer , van oord and many more .\n",
            "True Label: 0, Predicted Label: 1\n",
            "\n",
            "Sentence1: axl rose had wanted the seattle rock band nirvana to be the opening act , but frontman kurt cobain declined .\n",
            "Sentence2: axl rose had wanted the seattle rock band nirvana to be the opening act , but frontman kurt cobain declined .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: he built weapons factories for vtorov and mikhelson in moscow , serpukhov , zatishye ( elektrostal ) , bogorodsk ( noginsk ) .\n",
            "Sentence2: he built weapons factories for vtorov and mikhelson in moscow , serpukhov , zatishye ( elektrostal ) , bogorodsk ( noginsk ) .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: in june of 1997 , kristin met richard armstrong .\n",
            "Sentence2: in june of 1997 , kristin met richard armstrong .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: the u.s. route 191 leads north from douglas to interstate 10 near willcox , the arizona state route 80 leads west to bisbee and northeast to interstate 10 in new mexico .\n",
            "Sentence2: the u.s. route 191 leads north from douglas to interstate 10 near willcox , the arizona state route 80 leads west to bisbee and northeast to interstate 10 in new mexico .\n",
            "True Label: 1, Predicted Label: 0\n",
            "\n",
            "Sentence1: most jewish anarchists supported anarchosyndicalism and communist anarchism , while a few were individualist anarchists .\n",
            "Sentence2: most jewish anarchists supported anarchosyndicalism and communist anarchism , while a few were individualist anarchists .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n",
            "Sentence1: from 1921 to 2012 , blue ash airport was the location of blue ash airport -- cincinnati .\n",
            "Sentence2: from 1921 to 2012 , blue ash airport was the location of blue ash airport -- cincinnati .\n",
            "True Label: 0, Predicted Label: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEb0EaCBYxrb"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}