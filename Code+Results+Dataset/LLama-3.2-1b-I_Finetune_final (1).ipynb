{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03142a3-65fe-4996-bd2c-8492b0cbc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers\n",
    "# !pip install --upgrade transformers accelerate peft bitsandbytes\n",
    "# !pip install datasets\n",
    "# !pip install scikit-learn\n",
    "# !pip install evaluate\n",
    "##!pip install tf-keras\n",
    "#!pip install wandb\n",
    "#import os\n",
    "\n",
    "# Set the WIND_API_KEY environment variable\n",
    "#os.environ['WIND_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c84169c-2b6e-4f51-8629-e794102997c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import optuna\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d20ad1-1cba-4ed0-ba7c-c0a7f35e4b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_final = load_dataset(\"glue\", \"mrpc\")\n",
    "labeled_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7749a616-d90c-4614-ac2d-5d73680ea36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove noise\n",
    "def remove_noise(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove special patterns like \"< .SPX >\", \"< .IXIC >\"\n",
    "    text = re.sub(r'< \\.[A-Z]+ >', '', text)\n",
    "    \n",
    "    # Remove ellipsis (...)\n",
    "    text = re.sub(r'\\.\\s*\\.\\s*\\.+', ' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove special characters like \"â€™\", \"Â½\", \"Â£\", etc.\n",
    "    text = re.sub(r'[â€™Â½Â£]', '', text)\n",
    "    \n",
    "    # Remove single alphabets (e.g., \"C\")\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    \n",
    "    # Remove equal (=) sign at the end\n",
    "    text = re.sub(r'=$', '', text)\n",
    "    \n",
    "    # Remove double hyphens (--)\n",
    "    text = re.sub(r'--+', '', text)\n",
    "    \n",
    "    # Remove unwanted quotes\n",
    "    text = re.sub(r'[\"“”]', '', text)\n",
    "\n",
    "    # Fix short words with apostrophes (e.g., \"'re\" -> \"are\")\n",
    "    text = re.sub(r\"\\s+'re\\b\", \" are\", text)\n",
    "    text = re.sub(r\"\\b're\\b\", \"are\", text)\n",
    "    text = re.sub(r\"\\b've\\b\", \"have\", text)\n",
    "    text = re.sub(r\"\\b'll\\b\", \"will\", text)\n",
    "    text = re.sub(r\"\\b'd\\b\", \"would\", text)\n",
    "    text = re.sub(r\"\\b'm\\b\", \"am\", text)\n",
    "    text = re.sub(r\"\\b's\\b\", \"is\", text)\n",
    "    text = re.sub(r\"\\b'n\\b\", \"and\", text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_noise_batch(examples):\n",
    "    examples[\"cleaned_sentence1\"] = [remove_noise(sentence) for sentence in examples[\"sentence1\"]]\n",
    "    examples[\"cleaned_sentence2\"] = [remove_noise(sentence) for sentence in examples[\"sentence2\"]]\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc0ee207-d49b-4876-b382-cc9c9dba3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset=labeled_final.map(remove_noise_batch, batched=True)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a91fff0-4aed-4969-ad04-353f935436bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define text preprocessing function\n",
    "# def preprocess_text(data):\n",
    "#     contractions = {\"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"}\n",
    "\n",
    "#     def clean_sentence(sentence):\n",
    "#         # 1. Remove extra spaces\n",
    "#         sentence = re.sub(r'\\s+', ' ', sentence.strip())\n",
    "\n",
    "#         # 2. Remove URLs\n",
    "#         sentence = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', sentence)\n",
    "\n",
    "#         # 3. Remove special characters and punctuation (except dots)\n",
    "#         sentence = re.sub(r\"[^\\w\\s.]\", '', sentence)\n",
    "\n",
    "#         # 4. Remove consecutive dots\n",
    "#         sentence = re.sub(r'\\.{3,}', ' ', sentence)\n",
    "\n",
    "#         # 5. Convert to lowercase\n",
    "#         sentence = sentence.lower()\n",
    "\n",
    "#         # 6. Normalize contractions\n",
    "#         sentence = ' '.join([contractions[word] if word in contractions else word for word in sentence.split()])\n",
    "\n",
    "#         return sentence\n",
    "\n",
    "#     for eachsent in range(len(data['sentence1'])):\n",
    "#         data['sentence1'][eachsent] = clean_sentence(data['sentence1'][eachsent])\n",
    "\n",
    "#     for eachsent in range(len(data['sentence2'])):\n",
    "#         data['sentence2'][eachsent] = clean_sentence(data['sentence2'][eachsent])\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "353439e4-bff2-449b-91e6-7b3e629561fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = labeled_final[\"train\"].map(remove_noise_batch, batched=True)\n",
    "valid_dataset = labeled_final[\"validation\"].map(remove_noise_batch, batched=True)\n",
    "test_dataset = labeled_final[\"test\"].map(remove_noise_batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "642d98bb-0ff1-479f-afb8-6c9034512ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'cleaned_sentence1', 'cleaned_sentence2'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41529176-7901-4e3f-92ec-017d100e57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train_dataset.select(range(1000))\n",
    "# valid = valid_dataset.select(range(100))\n",
    "# test = test_dataset.select(range(50))\n",
    "#---\n",
    "train = train_dataset\n",
    "valid = valid_dataset\n",
    "test = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56db88df-96b2-4453-8ba4-7ec5a7140209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0,\n",
       " 'cleaned_sentence1': 'amrozi accused his brother , whom he called  the witness  , of deliberately distorting his evidence .',\n",
       " 'cleaned_sentence2': 'referring to him as only  the witness  , amrozi accused his brother of deliberately distorting his evidence .'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75c83c-ee1f-42c8-a525-794ec941758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN=\"\"\n",
    "from huggingface_hub import login\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e282115-ca7f-42d7-9c66-8936d4261cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ab16bc4-120a-4a20-8351-cb484cdecc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Incase of quantization\n",
    "# import torch\n",
    "# from transformers import BitsAndBytesConfig\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "# Define QLORA configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Use 4-bit precision\n",
    "    bnb_4bit_use_double_quant=True,  # Double quantization for stability\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Quantization type (e.g., NormalFloat4)\n",
    "    bnb_4bit_compute_dtype=torch.float16  # Computation type\n",
    ")\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                          # Low-rank size\n",
    "    lora_alpha=32,                # LoRA scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers (specific to LLaMA)\n",
    "    lora_dropout=0.12,             # Dropout for LoRA layers\n",
    "    bias=\"none\",                  # No bias adaptation\n",
    "    task_type=\"SEQ_CLS\"         # Task type: causal language modeling ###'SEQ_CLS' ###CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=2,  # Explicitly set for binary classification\n",
    "    device_map=\"auto\"  # Automatically distribute layers across available GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "907d6193-ab73-4d6a-891e-b9045abc9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the prepare_model_for_kbit_training() function to preprocess the quantized model for training.\n",
    "# from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "#use the get_peft_model() function to create a PeftModel from the quantized model and configuration.\n",
    "# from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fa0ee1e-7591-4fbc-a9c4-b8a994cd2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ada8ecf5-1ff0-415a-a03c-2fcb2d903607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure tokenizer has a pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    print(\"Padding token added as [PAD].\")\n",
    "\n",
    "# Resize model embeddings if new token is added\n",
    "if tokenizer.pad_token_id is not None and model.get_input_embeddings().num_embeddings != len(tokenizer):\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set pad_token_id in model configuration\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"cleaned_sentence1\"],\n",
    "        examples[\"cleaned_sentence2\"],\n",
    "        padding=True,  # Use padding\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_train_dataset = train.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49385a09-7e52-43cc-8e85-31023f147760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'cleaned_sentence1', 'cleaned_sentence2', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ebcbe0c-8042-4119-bcca-de6a7b7c2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_dataset = test.map(tokenize_function, batched=True)\n",
    "tokenized_valid_dataset = valid.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ddde8c6-a23e-4055-8ca0-d218a10b0079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the necessary features\n",
    "tokenized_train_dataset = tokenized_train_dataset.map(\n",
    "    lambda examples: {\n",
    "        \"input_ids\": examples[\"input_ids\"],\n",
    "        \"attention_mask\": examples[\"attention_mask\"],\n",
    "        \"labels\": examples[\"label\"]\n",
    "    },\n",
    "    remove_columns=[\"idx\", \"sentence1\", \"sentence2\", \"label\",'cleaned_sentence1', 'cleaned_sentence2']\n",
    ")\n",
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4359b36e-e45f-4671-a5b3-5a64f494e67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['cleaned_sentence1', 'cleaned_sentence2', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 408\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the necessary features\n",
    "tokenized_valid_dataset = tokenized_valid_dataset.map(\n",
    "    lambda examples: {\n",
    "        \"input_ids\": examples[\"input_ids\"],\n",
    "        \"attention_mask\": examples[\"attention_mask\"],\n",
    "        \"labels\": examples[\"label\"]\n",
    "    },\n",
    "    remove_columns=[\"idx\", \"sentence1\", \"sentence2\", \"label\"]\n",
    ")\n",
    "\n",
    "tokenized_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bee2c83-be8b-4f65-9b23-addcd302615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for padding\n",
    "# from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b97ad028-af2f-43f1-88eb-c810d3211d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_llama3.2-1B\",         # Output directory for saved models\n",
    "    learning_rate=2e-4,          # Learning rate\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    per_device_train_batch_size=16, # Training batch size\n",
    "    per_device_eval_batch_size=16, # Evaluation batch size\n",
    "    num_train_epochs=15,            # Number of training epochs\n",
    "    weight_decay=0.1,             # Weight decay\n",
    "    warmup_steps=250,\n",
    "    #save_total_limit=2,            # Save only the 2 most recent models\n",
    "    logging_dir=\"./logs\",          # Log directory\n",
    "    logging_steps=25,              # Log every 50 steps\n",
    "    load_best_model_at_end=True,    # Load the best model at the end of training\n",
    "    eval_strategy=\"epoch\",   # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",         # Change save_strategy to 'epoch' to match eval_strategy\n",
    "    gradient_accumulation_steps=4, # Added gradient accumulation\n",
    "    fp16=True,                       # Enabled mixed precision training\n",
    "    gradient_checkpointing=True,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81476632-9127-4269-90d2-f7166c116a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,708,032 || all params: 1,237,526,528 || trainable%: 0.1380\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0a59849-578d-410a-a50e-87d2a18839ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a metric function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # Get the class with the highest score\n",
    "\n",
    "    # Calculate accuracy, precision, recall, and F1\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# # Metrics\n",
    "# metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     results = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "#     print(f\"Results keys: {results.keys()}\") #add this line\n",
    "\n",
    "#     accuracy = results[\"accuracy\"]\n",
    "#     f1 = results[\"f1\"]\n",
    "#     precision = results.get(\"precision\", None)\n",
    "#     recall = results.get(\"recall\", None)\n",
    "\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy,\n",
    "#         \"f1\": f1,\n",
    "#         \"precision\": precision,\n",
    "#         \"recall\": recall,\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6c6a232-9f4c-47b5-ac8c-ef15534bf8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import EarlyStoppingCallback\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a718eb4-8741-4914-b218-e5efa2d8be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_valid_dataset,  # Assuming you have a validation set\n",
    "    #tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37b7d9dc-66c1-4c75-b4ee-390e94e79dd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='522' max='855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [522/855 10:51 < 06:57, 0.80 it/s, Epoch 9/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.995300</td>\n",
       "      <td>0.773239</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.723618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594300</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.834951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>0.560750</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.766734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.476347</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>0.773256</td>\n",
       "      <td>0.953405</td>\n",
       "      <td>0.853933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.433941</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.205100</td>\n",
       "      <td>0.408825</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.883636</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.877256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.664317</td>\n",
       "      <td>0.825980</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.910394</td>\n",
       "      <td>0.877375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.690690</td>\n",
       "      <td>0.818627</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.885305</td>\n",
       "      <td>0.869718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.932343</td>\n",
       "      <td>0.840686</td>\n",
       "      <td>0.876761</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.884547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=522, training_loss=0.3976029422548082, metrics={'train_runtime': 653.2181, 'train_samples_per_second': 84.229, 'train_steps_per_second': 1.309, 'total_flos': 1.834253490167808e+16, 'train_loss': 0.3976029422548082, 'epoch': 9.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f60b92b8-4eb2-4c51-87e5-7f12df0e11ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4088248312473297, 'eval_accuracy': 0.8333333333333334, 'eval_precision': 0.8836363636363637, 'eval_recall': 0.8709677419354839, 'eval_f1': 0.8772563176895307, 'eval_runtime': 2.3711, 'eval_samples_per_second': 172.071, 'eval_steps_per_second': 10.965, 'epoch': 9.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7fe91c6-44bc-463e-9d3e-40971b2b944b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.12, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.12, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2048, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2048, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d62a58-035d-4b73-8c95-544cf7b66ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
