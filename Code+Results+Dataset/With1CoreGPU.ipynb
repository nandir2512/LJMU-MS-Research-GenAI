{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1\n",
      "Uninstalling torch-2.5.1:\n",
      "  Successfully uninstalled torch-2.5.1\n",
      "Found existing installation: torchvision 0.17.2\n",
      "Uninstalling torchvision-0.17.2:\n",
      "  Successfully uninstalled torchvision-0.17.2\n",
      "Found existing installation: torchaudio 2.2.2\n",
      "Uninstalling torchaudio-2.2.2:\n",
      "  Successfully uninstalled torchaudio-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/torch-2.6.0.dev20241112%2Bcu121-cp310-cp310-linux_x86_64.whl (767.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.9/767.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchvision-0.20.0.dev20241112%2Bcu121-cp310-cp310-linux_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/torchaudio-2.5.0.dev20241112%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m196.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m204.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting pytorch-triton==3.1.0+cf34004b8a (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.1.0%2Bcf34004b8a-cp310-cp310-linux_x86_64.whl (239.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, pytorch-triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-cusparselt-cu12-0.6.2 nvidia-nvtx-cu12-12.1.105 pytorch-triton-3.1.0+cf34004b8a torch-2.6.0.dev20241112+cu121 torchaudio-2.5.0.dev20241112+cu121 torchvision-0.20.0.dev20241112+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0.dev20241112+cu121\n",
      "CUDA available: True\n",
      "GPU name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s9tRq_bSD2h2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31oKOET_EJkG",
    "outputId": "a6bbb78e-a802-411a-c0d2-97972043d9c7"
   },
   "outputs": [],
   "source": [
    "#! pip install datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZ6y8ghsEVJN",
    "outputId": "3d764319-929a-4e6f-8f6b-323223eec2a9"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load Subsets\n",
    "labeled_final = load_dataset(\"paws\", \"labeled_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7yEtwmzEbJx",
    "outputId": "7be55605-c55b-4251-b795-6ce042370159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 49401\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "H-5ZdtVYmOHW"
   },
   "outputs": [],
   "source": [
    "# # Access train, test, and validation splits\n",
    "# labeled_final_train = labeled_final[\"train\"]\n",
    "# labeled_final_test = labeled_final[\"test\"]\n",
    "# labeled_final_validation = labeled_final[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V96GIDqXlf_M"
   },
   "outputs": [],
   "source": [
    "# Define text preprocessing function\n",
    "def preprocess_text(data):\n",
    "  for eachsent in range(len(data['sentence1'])):\n",
    "\n",
    "    # 1. Remove extra spaces\n",
    "    data['sentence1'][eachsent] = re.sub(r'\\s+', ' ', data['sentence1'][eachsent].strip())\n",
    "\n",
    "    # 2. Remove unwanted text (e.g., URLs, special characters, digits)\n",
    "    data['sentence1'][eachsent] = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', data['sentence1'][eachsent])  # Remove URLs\n",
    "    #data['sentence1'][eachsent] = re.sub(r'[^\\w\\s]', '', data['sentence1'][eachsent])  # Remove special characters (punctuation)\n",
    "\n",
    "    # 3. Convert to lowercase\n",
    "    data['sentence1'][eachsent] = data['sentence1'][eachsent].lower()\n",
    "\n",
    "    # 4. Normalize text (e.g., contractions)\n",
    "    contractions = {\"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"}\n",
    "    data['sentence1'][eachsent] = ' '.join([contractions[word] if word in contractions else word for word in data['sentence1'][eachsent].split()])\n",
    "\n",
    "\n",
    "  for eachsent in range(len(data['sentence2'])):\n",
    "\n",
    "    # 1. Remove extra spaces\n",
    "    data['sentence2'][eachsent] = re.sub(r'\\s+', ' ', data['sentence2'][eachsent].strip())\n",
    "\n",
    "    # 2. Remove unwanted text (e.g., URLs, special characters, digits)\n",
    "    data['sentence2'][eachsent] = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', data['sentence2'][eachsent])  # Remove URLs\n",
    "    #data['sentence2'][eachsent] = re.sub(r'[^\\w\\s]', '', data['sentence2'][eachsent])  # Remove special characters (punctuation)\n",
    "\n",
    "    # 3. Convert to lowercase\n",
    "    data['sentence2'][eachsent] = data['sentence2'][eachsent].lower()\n",
    "\n",
    "    # 4. Normalize text (e.g., contractions)\n",
    "    contractions = {\"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"}\n",
    "    data['sentence2'][eachsent] = ' '.join([contractions[word] if word in contractions else word for word in data['sentence2'][eachsent].split()])\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cWNdB7aQlnV8"
   },
   "outputs": [],
   "source": [
    "train_dataset = labeled_final[\"train\"].map(preprocess_text, batched=True)\n",
    "valid_dataset = labeled_final[\"validation\"].map(preprocess_text, batched=True)\n",
    "test_dataset = labeled_final[\"test\"].map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "txQCAfdbEea2"
   },
   "outputs": [],
   "source": [
    "# train = labeled_final['train'].select(range(500))\n",
    "# test = labeled_final['test'].select(range(50))\n",
    "# valid = labeled_final['validation'].select(range(50))\n",
    "\n",
    "train = train_dataset.select(range(500))\n",
    "valid = valid_dataset.select(range(50))\n",
    "test = test_dataset.select(range(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "movzRa15Emlj",
    "outputId": "2a5875de-02d9-45a9-c5f1-5c07dd5526f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'sentence1': 'in paris , in october 1560 , he secretly met the english ambassador , nicolas throckmorton , asking him for a passport to return to england through scotland .',\n",
       " 'sentence2': 'in october 1560 , he secretly met with the english ambassador , nicolas throckmorton , in paris , and asked him for a passport to return to scotland through england .',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YIsyFV_1GTEE"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# HF_TOKEN= userdata.get('HuggingFace')\n",
    "HF_TOKEN=\"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\"\n",
    "from huggingface_hub import login\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oGIyf_iwHfkn"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw9Vgwlj3GlX"
   },
   "source": [
    "Since LLAMA3 pre-training doesn't have EOS token\n",
    "* Set the pad_token_id to eos_token_id\n",
    "* Set pad token ot eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZclzrnCqFAvn"
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# # Load the model\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJPWlR9Ekt10",
    "outputId": "0e37dabe-ec5e-4935-c718-8b550d3bd973",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes\n",
    "# !pip install -U torch peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y torch torchvision torchaudio\n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu<your_cuda_version>/cu<your_cuda_version>/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jbWjN-piTpS",
    "outputId": "93020ce8-cc59-4c5e-f0a2-f70297d62ed5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d2fa4560174d8f88934e0f1db02a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6325801957434e12834cef39fe81d1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# # Incase of quantization\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "# Define QLORA configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Use 4-bit precision\n",
    "    bnb_4bit_use_double_quant=True,  # Double quantization for stability\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Quantization type (e.g., NormalFloat4)\n",
    "    bnb_4bit_compute_dtype=torch.float16  # Computation type\n",
    ")\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                          # Low-rank size\n",
    "    lora_alpha=32,                # LoRA scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers (specific to LLaMA)\n",
    "    lora_dropout=0.1,             # Dropout for LoRA layers\n",
    "    bias=\"none\",                  # No bias adaptation\n",
    "    task_type=\"SEQ_CLS\"         # Task type: causal language modeling ###'SEQ_CLS' ###CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=2,  # Explicitly set for binary classification\n",
    "    device_map=\"auto\"  # Automatically distribute layers across available GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JTLO9KZFyT3N"
   },
   "outputs": [],
   "source": [
    "#call the prepare_model_for_kbit_training() function to preprocess the quantized model for training.\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n",
    "#use the get_peft_model() function to create a PeftModel from the quantized model and configuration.\n",
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD5boHFW3SZE"
   },
   "source": [
    "Update some model configs\n",
    "* Must use .cache = False as below or it crashes from my experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "e5NlmHCL3VK1"
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8dUI3CiQMfH"
   },
   "outputs": [],
   "source": [
    "# # Freeze all model parameters except LoRA layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Enable gradients for LoRA layers\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"lora\" in name:\n",
    "#         param.requires_grad = True\n",
    "\n",
    "# # Check which parameters require gradients\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name} requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6ZF1J0VynNU"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7d644c4a0bd94b1e8483d8cbaedeb1cb",
      "9f3ad66ab32b4175b1ed7d503764a953",
      "a33d31da810b4ac484bf6bd4dbbe5f66",
      "f744d02ebf1344b387556389f8d610d0",
      "c9a2bd617e5d4eb18fc82074933f55da",
      "f445b678a85a4024a65dcb22a55922f1",
      "6fb2af99026d471e93775b5b72b9f343",
      "326d6e6e09194ab3bf6dd49b4399e0bc",
      "39a6765c11ba4cca822cdc3c993e6673",
      "cea3101ea2c44977ae4e77f6407ef881",
      "eb8054727f60470cad0822f57273197a"
     ]
    },
    "id": "LGfkF13QGkat",
    "outputId": "e13e3812-dde5-4884-a068-83204d760b14"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605597708a7a4b4a86a2f1a497e7d24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure tokenizer has a pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    print(\"Padding token added as [PAD].\")\n",
    "\n",
    "# Resize model embeddings if new token is added\n",
    "if tokenizer.pad_token_id is not None and model.get_input_embeddings().num_embeddings != len(tokenizer):\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set pad_token_id in model configuration\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence1\"],\n",
    "        examples[\"sentence2\"],\n",
    "        padding=\"max_length\",  # Use padding\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_train_dataset = train.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tygA1OJIB8x",
    "outputId": "5b81ba43-98b2-4a49-d823-e4ac09381e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentence1', 'sentence2', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BQ_9M2DHIc3d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac805fd6075e4ababeb2753d9163fea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2474c6a18484f69be78b98fe0058709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test_dataset = test.map(tokenize_function, batched=True)\n",
    "tokenized_valid_dataset = valid.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "9ab2d5fca2274cf9b3fcdcbdeff77f50",
      "3e7ca88eb11b4642b3c7954858134b03",
      "0535dd2e3d664829bb478aabefaa8a47",
      "9d3e74378d1c47b091e9dea226ad6221",
      "5800f812a3df4f9e98f1de435c439fe0",
      "369da3488a63477886d105164dfb7cd5",
      "416f0147dc6b4d08b550b13a9fe3de1a",
      "970f2dc4d63546b38cc29dd7cee8b0f6",
      "f15e55e45f8e4097a1e6749f114e7b39",
      "5e1edcbb7ee94493b5a48b6002480945",
      "1d10bed373ea4e4d8378ff727d418dd1"
     ]
    },
    "id": "rZG5RMq9JCUf",
    "outputId": "1be0881d-0231-4847-960a-47038d82f29a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f802b95ab044d629aaf365be6b3c92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the necessary features\n",
    "tokenized_train_dataset = tokenized_train_dataset.map(\n",
    "    lambda examples: {\n",
    "        \"input_ids\": examples[\"input_ids\"],\n",
    "        \"attention_mask\": examples[\"attention_mask\"],\n",
    "        \"labels\": examples[\"label\"]\n",
    "    },\n",
    "    remove_columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    ")\n",
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCLGlo0HJTGl",
    "outputId": "2260665b-b251-48e6-c366-2338fc53c6f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1318c89254ca4284b81f33f9aa1dd5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the necessary features\n",
    "tokenized_valid_dataset = tokenized_valid_dataset.map(\n",
    "    lambda examples: {\n",
    "        \"input_ids\": examples[\"input_ids\"],\n",
    "        \"attention_mask\": examples[\"attention_mask\"],\n",
    "        \"labels\": examples[\"label\"]\n",
    "    },\n",
    "    remove_columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    ")\n",
    "\n",
    "tokenized_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81b0LcPZJdBT",
    "outputId": "ff12c448-c2a9-4fd2-b4e4-95decc9df2d3"
   },
   "outputs": [],
   "source": [
    "# # Keep only the necessary features\n",
    "# tokenized_test_dataset = tokenized_test_dataset.map(\n",
    "#     lambda examples: {\n",
    "#         \"input_ids\": examples[\"input_ids\"],\n",
    "#         \"attention_mask\": examples[\"attention_mask\"],\n",
    "#         \"labels\": examples[\"label\"]\n",
    "#     },\n",
    "#     remove_columns=[\"id\", \"sentence1\", \"sentence2\", \"label\"]\n",
    "# )\n",
    "\n",
    "tokenized_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CJuMmxT2zMrL"
   },
   "outputs": [],
   "source": [
    "# Data collator for padding\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "70GeXdlTKwN5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# disable Weights and Biases\n",
    "os.environ['WANDB_DISABLED']=\"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFR3LQtfJihO",
    "outputId": "b4bfa708-dac1-48e8-abe5-30b1b93a60af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_lora\",         # Output directory for saved models\n",
    "    learning_rate=2e-5,          # Learning rate\n",
    "    per_device_train_batch_size=4, # Training batch size\n",
    "    per_device_eval_batch_size=4, # Evaluation batch size\n",
    "    num_train_epochs=5,            # Number of training epochs\n",
    "    weight_decay=0.01,             # Weight decay\n",
    "    #save_total_limit=2,            # Save only the 2 most recent models\n",
    "    logging_dir=\"./logs\",          # Log directory\n",
    "    logging_steps=50,              # Log every 50 steps\n",
    "    load_best_model_at_end=True,    # Load the best model at the end of training\n",
    "    eval_strategy=\"epoch\",   # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",         # Change save_strategy to 'epoch' to match eval_strategy\n",
    "    gradient_accumulation_steps=2, # Added gradient accumulation\n",
    "    #fp16=False,                       # Enabled mixed precision training\n",
    "    gradient_checkpointing=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARn_PCD7QboB",
    "outputId": "fc3ba8ba-57a8-4d7e-c0c5-8d69fa806d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 856,064 || all params: 1,236,674,560 || trainable%: 0.0692\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "O9Km97MtYGGl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Define a metric function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # Get the class with the highest score\n",
    "\n",
    "    # Calculate accuracy, precision, recall, and F1\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IkJJhz__Jtxt",
    "outputId": "7a66078e-a0ca-4900-c43b-99b5ed277c27"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_valid_dataset,  # Assuming you have a validation set\n",
    "    #tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyt8O7P0PYO5",
    "outputId": "b6e857d4-48cb-43fc-834e-0df6ea5c9112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 18 16:57:11 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   33C    P0             31W /   70W |    2139MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       321      C   ...conda3/envs/pytorch_p310/bin/python       2136MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "7rO1PIgHKkRP",
    "outputId": "9e38d085-26e7-4608-f389-858657f49070"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 09:12, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.765717</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.726700</td>\n",
       "      <td>0.735858</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.717210</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.580400</td>\n",
       "      <td>0.695749</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=310, training_loss=0.6632260584062145, metrics={'train_runtime': 554.3755, 'train_samples_per_second': 4.51, 'train_steps_per_second': 0.559, 'total_flos': 1843162716831744.0, 'train_loss': 0.6632260584062145, 'epoch': 4.928})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "UP0UkOrJKk06",
    "outputId": "5d4eeb00-1179-40f4-99e2-fbed94d42929"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6957489252090454, 'eval_accuracy': 0.6, 'eval_precision': 0.6153846153846154, 'eval_recall': 0.6153846153846154, 'eval_f1': 0.6153846153846154, 'eval_runtime': 3.6821, 'eval_samples_per_second': 13.579, 'eval_steps_per_second': 3.531, 'epoch': 4.928}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SjSMUUBBXlKg",
    "outputId": "461ba68d-9848-4c43-9e04-e0e1caa10f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.64, 'precision': 0.5238095238095238, 'recall': 0.5789473684210527, 'f1': 0.55}\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.predict(tokenized_test_dataset)\n",
    "metrics = compute_metrics(test_results)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zcyXI-EYxBr",
    "outputId": "71b66bb3-a1b5-4312-8b9b-576104fdcc6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence1: this was a series of nested angular standards , so that measurements in azimuth and elevation could be done directly in polar coordinates relative to the ecliptic .\n",
      "Sentence2: this was a series of nested polar scales , so that measurements in azimuth and elevation could be performed directly in angular coordinates relative to the ecliptic .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: his father emigrated to missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to america .\n",
      "Sentence2: his father emigrated to america in 1868 , but returned when his wife became ill and before the rest of the family could go to missouri .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: in january 2011 , the deputy secretary general of fiba asia , hagop khajirian , inspected the venue together with sbp - president manuel v. pangilinan .\n",
      "Sentence2: in january 2011 , fiba asia deputy secretary general hagop khajirian along with sbp president manuel v. pangilinan inspected the venue .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: steiner argued that , in the right circumstances , the spiritual world can be explored through direct experience by practicing ethical and cognitive forms of rigorous self-discipline .\n",
      "Sentence2: steiner held that the spiritual world can be researched in the right circumstances through direct experience , by persons practicing rigorous forms of ethical and cognitive self-discipline .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: luciano williames dias ( born july 25 , 1970 ) is a brazilian football coach and former player .\n",
      "Sentence2: luciano williames dias ( born 25 july 1970 ) is a former football coach and brazilian player .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: during her sophomore , junior and senior summers , she spent half of it with her alaska team , and half playing , and living in oregon .\n",
      "Sentence2: during her second , junior and senior summers , she spent half of it with her alaska team , half playing and living in oregon .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: the smallest number that can be represented in two positive and seventh ways as a sum of four different powers is 2056364173794800 .\n",
      "Sentence2: the smallest number that can be represented as a sum of four positive seventh potences in two different ways is 2056364173794800 .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: his father emigrated to missouri in 1868 , but returned when his wife became ill and before the rest of the family could go to america .\n",
      "Sentence2: his father emigrated to missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to america .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: the villa pesquera facilities are owned by the municipality of ponce , but operated by the fishermen themselves .\n",
      "Sentence2: the facilities of villa pesquera are operated by the municipality of ponce , but are owned by the fishermen .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: it is situated south of köroğlu mountains and to the north of bolu .\n",
      "Sentence2: it is situated south of köroğlu - mountains and north of the bolu .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: the río blanco mine is a large copper mine located in the north of peru in loreto region .\n",
      "Sentence2: the río blanco - mine is a large copper mine in northern peru in the region of loreto .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: he appeared as general tao in the amazon - show `` the man at the high castle '' , and as onoda in amc `` hell on wheels '' .\n",
      "Sentence2: he appeared as general onoda in the amazon - show `` the man in high castle '' and as tao on amcs '' hell on wheels '' .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: the spectral levels of light that can be measured by plants for photosynthesis is similar to , but not the same as what  is used by lumens .\n",
      "Sentence2: the spectral light levels that can be measured by plants for photosynthesis are similar , but not the same as what is used by lumens .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: the sunset sunset road comes from right and becomes briscoe mountain road .\n",
      "Sentence2: sunset road comes in from the right and becomes briscoe mountain road .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: to get there , take the marine drive from the lions gate bridge to the west , past lighthouse park , horseshoe bay and then further on to the 7100 marine drive block .\n",
      "Sentence2: to get there , take marine drive west from the lions gate bridge past horseshoe bay to lighthouse park and then continue on to 7100 block marine drive .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: inverallan is one of the parishes which formed the ecclesiastical ( later civil ) parish of `` cromdale , inverallan and advie '' in morayshire in scotland .\n",
      "Sentence2: inverallan is one of the parishes that formed the civil ( later ecclesiastical ) parish of cromdale , inverallan and advie in morayshire , scotland .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: mr. thuso nokwanda mbedu was born in pietermaritzburg as thuso mbebu .\n",
      "Sentence2: thuso nokwanda mbedu was born thuso mbebu in pietermaritzburg .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: for ideal gases , the molar volume is given by the ideal gas equation , a good approximation for many usual gases at standard temperature and pressure .\n",
      "Sentence2: for ideal gases the molar volume is given by the standard gas equation , a good approximation for many common gases at ideal temperature and pressure .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: john barrow island is a member of the queen elizabeth islands and the canadian arctic archipelago in the territory of nunavut .\n",
      "Sentence2: john barrow island is a member of the canadian arctic archipelago and the queen elizabeth islands in the nunavut area .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: it was chosen as the 19th best movie at the 7th yokohama film festival .\n",
      "Sentence2: it was chosen as the 7th best film at the 19th yokohama film festival .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: christopher griffiths ( born christopher llewellyn ) is an actor , best known for his role as logan in the 2002 film `` where were we ... '' .\n",
      "Sentence2: christopher llewellyn ( born christopher griffiths ) is an actor known for his role as logan in the film 'where were we ... `` ' from the year 2002 .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: netanya is located on the israeli mediterranean coastal plain , the historic land bridge between europe , africa , and asia .\n",
      "Sentence2: netanya is located on the israeli mediterranean coast , the historic land bridge between europe , africa and asia .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: owned by rick and sheri dorritie is megasaurus and owned by mike west transaurus .\n",
      "Sentence2: megasaurus is owned by rick and sheri dorritie and transaurus is owned by mike west .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: all five events started the last day and concluded with the final on the first day .\n",
      "Sentence2: all five events started on the last day and concluded with the final on the first day .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: in january 2011 , fiba asia deputy secretary general manuel v. pangilinan along with sbp president hagop khajirian inspected the venue .\n",
      "Sentence2: in january 2011 , the deputy secretary general of fiba asia , hagop khajirian , inspected the venue together with sbp - president manuel v. pangilinan .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: the strong influence of attic-figure greek vase painting has convinced some experts that the artist who decorated the tomb was a red metic .\n",
      "Sentence2: the strong influence of redfigurine attic vase painting has convinced some experts that the artist who decorated the tomb was a greek metic .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: a unique feature of the human metate is the lack of ceremonial figures .\n",
      "Sentence2: a unique feature of ceremonial metate is the lack of human figures .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: durr was born in birmingham , alabama , where she was brought up by southern women , but was also taught that the ku klux klan were protectors of black femaleness .\n",
      "Sentence2: durr was born in birmingham , alabama , where she was brought up by black women , but was also taught that the ku klux klan were protectors of southern femininity .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: katrina m. of sputinik music was positive and said that the song is reverse , bright and cheerful .\n",
      "Sentence2: katrina m. of sputinik music was bright and cheerful and said the song is reversed , positive .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: the nokasippi river , the mississippi river and the little nokasippi river are all in the area .\n",
      "Sentence2: the mississippi , the nokasippi and the little nokasippi are all in the vicinity .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: in 2006 , the álvarez won the south america games against hamilton ventura .\n",
      "Sentence2: hamilton ventura won the 2006 south america games against álvarez .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: some reports state `` 30 years or more '' , while others claim `` 50 years or more '' .\n",
      "Sentence2: some reports claim `` 30 years or more '' , while others assert `` 50 years or more '' .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: the resignation of councillor horace muspratt ( party ? , st. peter , reported april 15 , 1908 ) was elected to the council on 2 june 1909 .\n",
      "Sentence2: the resignation of councillor horace muspratt ( party ? , st. peter  is , reported 15 april 1908 ) was elected to the council on 2 june 1909 .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: on april 11 , 2011 , a like planet , hd 38283 b , was discovered in an earth-saturnian orbit .\n",
      "Sentence2: in an earth-like orbit , a saturn planet , hd 38283 b , was discovered on april 11 , 2011 .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: on july 21 , 2014 , after his two successful years at las palmas in spain , chrisantus signed a three-year contract with the turkish super lig - club sivasspor .\n",
      "Sentence2: on july 21 , 2014 , after his two successful years at las palmas in spain , chrisantus signed a three-year contract with sivasspor at the turkish super lig .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: ruben bolling ( born 1963 in new jersey ) is a pseudonym for cartoonist ken fisher , the author of `` tom the dancing bug '' .\n",
      "Sentence2: ken fisher ( born c. 1963 in new jersey ) is a pseudonym for ruben bolling , a cartoonist , the author of `` tom the dancing bug '' .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: on december 1 , tinnish announced that he had withdrawn from his position with toronto and would stay with atlanta .\n",
      "Sentence2: on 1 december , tinnish announced that he had withdrawn from his position with atlanta and would remain with toronto .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: located in the southern part of the county , it lies in the southeastern part of the state .\n",
      "Sentence2: it is located in the southeastern part of the county , in the southern part of the state .\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Sentence1: he was born in new york city in east broadway on october 23 , 1806 .\n",
      "Sentence2: he was born on 23 october 1806 in new york , east broadway .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: he always added his own surname of bhosle and then treated the child like his own son .\n",
      "Sentence2: he always added his own surname of bhosle and afterwards treated the child like his own son .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: after selling his house on 30 harare drive to the canadian embassy he bought bromley farm just outside marondera , zimbabwe .\n",
      "Sentence2: after selling his house on 30 harare ride to the canadian embassy , he bought bromley farm outside marondera , zimbabwe .\n",
      "True Label: 1, Predicted Label: 0\n",
      "\n",
      "Sentence1: the baldwins lived in washington , d.c. robert baldwin died in 1977 , and helen baldwin died march 14 , 1998 , from lou gehrig  is disease .\n",
      "Sentence2: the baldwins lived in washington , d.c. helen baldwin died in 1977 , and robert baldwin died on march 14 , 1998 , from the disease of lou gehrig .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: doyline is an entry point to lake bistineau and the bistineau state park .\n",
      "Sentence2: lake bistineau is an entry point to doyline and the lake bistineau state park .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: companies based in the larger rivium include rockwell automation , royal dutch shell , sodexho nederland , pfizer , van oord and many more .\n",
      "Sentence2: companies based in the larger rivium include rockwell automation , pfizer nederland , sodexho nederland , royal dutch shell , van oord , and many more .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: axl rose had wanted the seattle rock band nirvana to be the opening act , but frontman kurt cobain declined .\n",
      "Sentence2: axl rose had wanted seattle rock band nirvana to be the opening act , but frontman kurt cobain refused .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: he built weapons factories for vtorov and mikhelson in moscow , serpukhov , zatishye ( elektrostal ) , bogorodsk ( noginsk ) .\n",
      "Sentence2: he built weapon factories for vtorov and mikhelson in electrostal , zatishye ( moscow , serpukhov ) and bogorodsk ( noginsk ) .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: in june of 1997 , kristin met richard armstrong .\n",
      "Sentence2: in june of 1997 , armstrong met kristin richard .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: the u.s. route 191 leads north from douglas to interstate 10 near willcox , the arizona state route 80 leads west to bisbee and northeast to interstate 10 in new mexico .\n",
      "Sentence2: u.s. route 191 leads north from douglas to interstate 10 near willcox . arizona state route 80 leads west to bisbee and northeast to interstate 10 in new mexico .\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Sentence1: most jewish anarchists supported anarchosyndicalism and communist anarchism , while a few were individualist anarchists .\n",
      "Sentence2: most individualist anarchists supported anarchosyndicalism and communist anarchism , while a few jewish anarchists were .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Sentence1: from 1921 to 2012 , blue ash airport was the location of blue ash airport -- cincinnati .\n",
      "Sentence2: from 1921 to 2012 , cincinnati -- blue ash airport was the blue blue ash site .\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "predictions = test_results.predictions.argmax(-1)  # Predicted labels\n",
    "true_labels = test_results.label_ids               # True labels\n",
    "\n",
    "# Pair predictions with true labels\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Sentence1: {tokenized_test_dataset[i]['sentence1']}\")\n",
    "    print(f\"Sentence2: {tokenized_test_dataset[i]['sentence2']}\")\n",
    "    print(f\"True Label: {true_labels[i]}, Predicted Label: {predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEb0EaCBYxrb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0535dd2e3d664829bb478aabefaa8a47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_970f2dc4d63546b38cc29dd7cee8b0f6",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f15e55e45f8e4097a1e6749f114e7b39",
      "value": 1000
     }
    },
    "1d10bed373ea4e4d8378ff727d418dd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "326d6e6e09194ab3bf6dd49b4399e0bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "369da3488a63477886d105164dfb7cd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39a6765c11ba4cca822cdc3c993e6673": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e7ca88eb11b4642b3c7954858134b03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_369da3488a63477886d105164dfb7cd5",
      "placeholder": "​",
      "style": "IPY_MODEL_416f0147dc6b4d08b550b13a9fe3de1a",
      "value": "Map: 100%"
     }
    },
    "416f0147dc6b4d08b550b13a9fe3de1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5800f812a3df4f9e98f1de435c439fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1edcbb7ee94493b5a48b6002480945": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb2af99026d471e93775b5b72b9f343": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d644c4a0bd94b1e8483d8cbaedeb1cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f3ad66ab32b4175b1ed7d503764a953",
       "IPY_MODEL_a33d31da810b4ac484bf6bd4dbbe5f66",
       "IPY_MODEL_f744d02ebf1344b387556389f8d610d0"
      ],
      "layout": "IPY_MODEL_c9a2bd617e5d4eb18fc82074933f55da"
     }
    },
    "970f2dc4d63546b38cc29dd7cee8b0f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ab2d5fca2274cf9b3fcdcbdeff77f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e7ca88eb11b4642b3c7954858134b03",
       "IPY_MODEL_0535dd2e3d664829bb478aabefaa8a47",
       "IPY_MODEL_9d3e74378d1c47b091e9dea226ad6221"
      ],
      "layout": "IPY_MODEL_5800f812a3df4f9e98f1de435c439fe0"
     }
    },
    "9d3e74378d1c47b091e9dea226ad6221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e1edcbb7ee94493b5a48b6002480945",
      "placeholder": "​",
      "style": "IPY_MODEL_1d10bed373ea4e4d8378ff727d418dd1",
      "value": " 1000/1000 [00:00&lt;00:00, 3606.05 examples/s]"
     }
    },
    "9f3ad66ab32b4175b1ed7d503764a953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f445b678a85a4024a65dcb22a55922f1",
      "placeholder": "​",
      "style": "IPY_MODEL_6fb2af99026d471e93775b5b72b9f343",
      "value": "Map: 100%"
     }
    },
    "a33d31da810b4ac484bf6bd4dbbe5f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_326d6e6e09194ab3bf6dd49b4399e0bc",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39a6765c11ba4cca822cdc3c993e6673",
      "value": 1000
     }
    },
    "c9a2bd617e5d4eb18fc82074933f55da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cea3101ea2c44977ae4e77f6407ef881": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb8054727f60470cad0822f57273197a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f15e55e45f8e4097a1e6749f114e7b39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f445b678a85a4024a65dcb22a55922f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f744d02ebf1344b387556389f8d610d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cea3101ea2c44977ae4e77f6407ef881",
      "placeholder": "​",
      "style": "IPY_MODEL_eb8054727f60470cad0822f57273197a",
      "value": " 1000/1000 [00:00&lt;00:00, 2716.58 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
